# 月面跳跃机器人构型设计和优化指南

## 概述
如果想做月面跳跃机器人相关的构型设计和优化，需要系统地理解DERL（Deep Evolutionary Reinforcement Learning）框架。本指南详细说明需要关注的关键文件和函数。

---

## 第一部分：核心架构理解

### 1.1 系统总体设计流程
```
配置文件 (config.yml)
    ↓
morphology.py (构型生成和突变)
    ↓
环境任务 (task.py 和具体任务)
    ↓
PPO训练 (ppo.py)
    ↓
进化算法 (evo_single_proc.py)
```

---

## 第二部分：必看文件详细清单

### 2.1 **构型设计核心文件** ⭐⭐⭐⭐⭐

#### 文件：`derl/envs/morphology.py`
**重要性**：最高 - 这是构型的基础

**需要重点关注的类**：
- **`SymmetricUnimal`** - 主类，管理整个机器人构型

**需要重点关注的函数**：

| 函数名 | 行号 | 用途 | 重要程度 |
|------|------|------|--------|
| `__init__` | 26-48 | 初始化unimal | ⭐⭐⭐⭐⭐ |
| `_init_new_unimal()` | 50-92 | 创建新机器人 | ⭐⭐⭐⭐⭐ |
| `_construct_head()` | 131-185 | 构建躯干头部 | ⭐⭐⭐⭐ |
| `_construct_limb()` | 187-330 | 构建单条肢体 | ⭐⭐⭐⭐⭐ |
| `grow_limb()` | 695-756 | **肢体生长突变** | ⭐⭐⭐⭐⭐ |
| `mutate_delete_limb()` | 413-463 | **肢体删除突变** | ⭐⭐⭐⭐⭐ |
| `mutate_limb_params()` | 475-548 | **肢体参数突变** | ⭐⭐⭐⭐ |
| `mutate_joint()` | 626-656 | **关节参数突变** | ⭐⭐⭐⭐ |
| `_choose_site()` | 862-901 | 选择生长点 | ⭐⭐⭐⭐ |
| `_get_new_limbs()` | 760-820 | 获取新肢体 | ⭐⭐⭐⭐ |

**核心概念**：
- `limb_metadata` - 存储每条肢体的属性（方向、父级、关节轴等）
- `limb_list` - 管理肢体对称性
- `mirror_sites` - 对称站点映射
- 站点类型（`growth_site` vs `mirror_growth_site`）决定未来生长模式

---

### 2.2 **环境和任务配置** ⭐⭐⭐⭐⭐

#### 文件：`derl/config.py`
**重要性**：非常高 - 配置所有参数

**需要重点关注的配置段**：

| 配置项 | 行号 | 用途 | 对月面跳跃的影响 |
|------|------|------|--------|
| `LIMB.*` | 100-112 | 肢体参数范围 | 决定肢体尺寸和密度 |
| `BODY.*` | 34-65 | 身体参数 | 决定对称性、关节轴 |
| `TORSO.*` | 67-87 | 躯干参数 | 决定头部和躯干尺寸 |
| `ENV.*` | 114-160 | 环境任务参数 | 决定任务类型和奖励 |
| `TERRAIN.*` | 162-200 | 地形参数 | **月面模型关键** |
| `EVO.*` | 382-450 | 进化算法参数 | 决定进化策略 |

**月面特定配置**：
```python
# 需要添加或修改的参数
TERRAIN.GRAVITY = 1.62  # 月面重力 (地球的1/6)
LIMB.JUMP_FORCE_RANGE = [100, 500]  # 跳跃力度
ENV.FORWARD_REWARD_WEIGHT = 1.0  # 前进奖励权重
ENV.JUMP_HEIGHT_REWARD = 1.0  # 跳跃高度奖励（新增）
```

#### 文件：`configs/evo/ft.yml` 或创建新配置文件 `configs/evo/lunar_jump.yml`
**重要性**：高 - 进化训练配置

**需要配置的项**：
```yaml
OUT_DIR: './output/lunar_jump'
RNG_SEED: 1409
ENV_NAME: 'Unimal-v0'

EVO:
  IS_EVO: true
  SELECTION_CRITERIA: ["__reward__forward", "__reward__jump_height"]
  SELECTION_CRITERIA_OBJ: [-1, -1]
  INIT_POPULATION_SIZE: 64
  SEARCH_SPACE_SIZE: 2000

ENV:
  MODULES: ["Agent", "Terrain"]
  TASK: "lunar_jump"  # 新任务
  GRAVITY_SCALE: 0.165  # 月面重力
  
TERRAIN:
  SIZE: [100, 30, 1]
  GRAVITY: 1.62

LIMB:
  HEIGHT_RANGE: [0.1, 0.3, 0.05]
  RADIUS_RANGE: [0.03, 0.08, 0.01]
```

---

### 2.3 **任务设计** ⭐⭐⭐⭐⭐

#### 文件：`derl/envs/tasks/task.py`
**重要性**：高 - 任务注册

**关键函数**：
- `make_env()` - 主任务工厂函数
- `TASK_REGISTRY` - 任务注册表

**需要做的**：
1. 在这里注册新任务 `lunar_jump`

#### 文件：`derl/envs/tasks/locomotion.py`
**重要性**：高 - 参考实现

**关键函数**：
- `LocomotionTask.__init__()` - 初始化任务
- `LocomotionTask.step()` - 每步更新和奖励计算

**需要创建新文件**：`derl/envs/tasks/lunar_jump.py`

```python
# 新文件需要实现的类和函数
class LunarJumpTask(UnimalEnv, utils.EzPickle):
    def __init__(self, xml_str, unimal_id):
        # 初始化
        pass
    
    def step(self, action):
        # 关键：计算跳跃高度、距离、能量效率
        # 返回：observation, reward, done, info
        pass
    
    def _calculate_jump_height(self):
        # 计算跳跃高度（月面最关键的指标）
        pass
    
    def _calculate_jump_distance(self):
        # 计算跳跃距离
        pass

def make_env_lunar_jump(xml, unimal_id):
    env = LunarJumpTask(xml, unimal_id)
    # ... 添加wrappers
    return env
```

---

### 2.4 **PPO训练算法** ⭐⭐⭐

#### 文件：`derl/algos/ppo/ppo.py`
**重要性**：中等 - 控制策略训练

**需要了解的函数**：
- `PPO.__init__()` - 初始化PPO算法
- `PPO.collect_rollout()` - 收集轨迹
- `PPO.update()` - 策略更新
- `PPO.learn()` - 主训练循环

**为月面优化的关键改进**：
- 增加动作约束（限制跳跃频率）
- 增加能量消耗计算
- 支持群体跳跃模式

---

### 2.5 **进化算法** ⭐⭐⭐⭐⭐

#### 文件：`tools/evo_single_proc.py`
**重要性**：最高 - 负责构型进化

**需要重点关注的函数**：

| 函数名 | 行号范围 | 用途 | 对月面的影响 |
|------|--------|------|----------|
| `ppo_train()` | 40-130 | 训练单个个体 | 计算适应度 |
| `init_population()` | 135-180 | 初始化种群 | 生成基础构型 |
| `tournament_evolution()` | 185-250 | 进化搜索 | 生成新构型 |

**关键流程**：
1. 初始化种群 → 2. 训练每个个体 → 3. 评估适应度 → 4. 比赛选择 → 5. 突变生成 → 重复

**需要自定义的部分**：
```python
# 在ppo_train()中添加月面特定奖励
reward_metrics = {
    "forward_distance": ...,  # 水平距离
    "jump_height": ...,        # 跳跃高度
    "energy_efficiency": ...,  # 能量效率 = 高度/能量
    "stability": ...           # 着陆稳定性
}
```

---

### 2.6 **物理参数和约束** ⭐⭐⭐⭐

#### 文件：`derl/utils/geom.py`
**重要性**：中等 - 坐标和物理计算

**需要了解的函数**：
- `sph2cart()` - 球坐标转笛卡尔坐标（肢体生长计算）
- 其他几何计算函数

#### 文件：`derl/utils/mjpy.py`
**重要性**：中等 - MuJoCo仿真接口

**关键函数**：
- `mjsim_from_etree()` - 创建仿真环境
- `get_body_xpos()` - 获取身体位置
- 物理参数设置

---

## 第三部分：实现月面跳跃机器人的具体步骤

### 步骤1：创建月面环境配置
**文件**：创建 `configs/evo/lunar_jump.yml`

关键参数：
```yaml
GRAVITY: 1.62  # 月球重力加速度
TERRAIN.LUNAR_SURFACE: true  # 月面表面特性
```

### 步骤2：创建月面任务
**文件**：创建 `derl/envs/tasks/lunar_jump.py`

关键实现：
- 跳跃高度计算
- 跳跃距离计算  
- 着陆检测和稳定性评估
- 多周期跳跃支持

### 步骤3：定义适应度函数
**修改**：`tools/evo_single_proc.py`

关键指标：
- 单次最大跳跃高度
- 连续跳跃次数
- 总跳跃距离
- 能量效率

### 步骤4：调整构型约束
**修改**：`derl/config.py` 和 `derl/envs/morphology.py`

月面特殊约束：
- 肢体长度（低重力需要合理比例）
- 肢体粗细（与着陆稳定性相关）
- 关节强度（跳跃冲击力）
- 最大肢体数（复杂度控制）

### 步骤5：启动进化训练
**命令**：
```bash
python tools/evolution.py --config configs/evo/lunar_jump.yml
```

---

## 第四部分：关键代码改动清单

### 4.1 必须修改的文件

| 文件 | 改动类型 | 优先级 |
|------|--------|-------|
| `derl/config.py` | 添加月面配置项 | P0 |
| `derl/envs/tasks/task.py` | 注册新任务 | P0 |
| 创建新文件 `derl/envs/tasks/lunar_jump.py` | 实现任务 | P0 |
| `derl/envs/morphology.py` | 可能的约束调整 | P1 |
| `tools/evo_single_proc.py` | 自定义奖励 | P1 |
| 创建新配置 `configs/evo/lunar_jump.yml` | 配置 | P0 |

### 4.2 可选优化的文件

| 文件 | 优化方向 | 优先级 |
|------|--------|-------|
| `derl/algos/ppo/ppo.py` | 月面特定的策略 | P2 |
| `derl/envs/wrappers/hfield.py` | 月面表面奖励 | P2 |
| `derl/utils/geom.py` | 低重力物理计算 | P2 |

---

## 第五部分：关键函数调用链

### 进化流程

```
tools/evolution.py (main entry)
    ↓
evo_single_proc.init_population()
    ↓
    ↓← morphology.SymmetricUnimal() [创建个体]
    ↓
evo_single_proc.ppo_train(个体)
    ↓
    ↓← lunar_jump.make_env_lunar_jump() [创建环境]
    ↓
    ↓← ppo.PPO.learn() [训练个体]
    ↓
[保存奖励和构型元数据]
    ↓
evo_single_proc.tournament_evolution()
    ↓
[进行比赛选择]
    ↓
morphology.SymmetricUnimal.mutate() [生成新构型]
    ↓
├─ grow_limb()
├─ mutate_delete_limb()
├─ mutate_limb_params()
├─ mutate_joint()
└─ mutate_density()
```

### 单步推理流程

```
lunar_jump.LunarJumpTask.step(action)
    ↓
self.do_simulation(action)  [物理仿真]
    ↓
_calculate_jump_height()    [计算跳跃高度]
_calculate_jump_distance()  [计算跳跃距离]
_calculate_energy()         [计算能量消耗]
    ↓
[计算奖励]
    ↓
return observation, reward, done, info
```

---

## 第六部分：重要数据结构

### limb_metadata结构

```python
limb_metadata[limb_idx] = {
    "joint_axis": ["x", "y"],           # 关节方向
    "orient": (h, theta, phi),          # 球坐标方向
    "parent_name": "torso/0",           # 父节点
    "site": "torso/0",                  # 附着点
    "gear": {"x": 100, "y": 50}        # 齿轮比
}
```

### step()返回值结构

```python
observation = self._get_obs()  # 观测向量

info = {
    "__reward__forward": ...,    # 前进奖励
    "__reward__jump_height": ...,# 跳跃高度奖励
    "__reward__ctrl": ...,       # 控制代价
    "x_pos": ...,               # 位置
    "jump_height": ...,         # 跳跃高度
    "metric": ...               # 评估指标
}

reward = forward_reward - ctrl_cost + jump_reward
```

---

## 第七部分：调试和测试建议

### 1. 逐步测试
```python
# 测试构型生成
unimal = SymmetricUnimal(id_=0)
unimal.grow_limb()

# 测试任务
env = make_env_lunar_jump(xml_path)
obs = env.reset()
for _ in range(100):
    obs, reward, done, info = env.step(env.action_space.sample())
```

### 2. 可视化
```bash
# 保存视频
python -c "
from derl.envs.morphology import SymmetricUnimal
unimal = SymmetricUnimal(0)
unimal.save_image()
"
```

### 3. 指标监控
```python
# 在training中记录
metrics = {
    "avg_jump_height": [],
    "max_jump_distance": [],
    "energy_efficiency": [],
    "success_rate": []
}
```

---

## 第八部分：参考资源

### 关键论文和概念
1. **DERL原理**：进化+RL的混合方法
2. **MuJoCo物理**：关于坐标系、约束等
3. **跳跃机制**：脉冲生成、着陆缓冲

### 代码示例位置
- 基础locomotion任务：`derl/envs/tasks/locomotion.py`
- 操纵任务示例：`derl/envs/tasks/manipulation.py`
- 复杂地形：`derl/envs/tasks/obstacle.py`

---

## 总结

### 按优先级学习顺序：
1. **最先**：`morphology.py` - 理解构型如何生成和变化
2. **其次**：`config.py` - 理解参数配置
3. **然后**：现有任务（如`locomotion.py`）- 理解任务框架
4. **最后**：`evo_single_proc.py` - 理解进化搜索

### 核心改动只需3个文件：
1. 创建 `lunar_jump.py` - 定义任务
2. 修改 `task.py` - 注册任务
3. 修改 `config.py` - 添加参数

其他文件的改动都是可选的优化！
